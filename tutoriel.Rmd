---
title: "Atelier Statistiques Avancées"
subtitle: "28e Colloque du Chapitre Saint-Laurent"
author:
  name: "Maxime Fraser Franco"
  affiliation: |
    Département des Sciences Biologiques \n Université du Québec à Montréal (UQAM)
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  rmdformats::readthedown:
    df_print: paged
    code_folding: show
bibliography: refs.bib
nocite: |
  @McElreath2020
  @Burkner2017
  @Burkner2018
  @Piironen.Vehtari2017
  @aczelDiscussionPointsBayesian2020
  @kruschkeBayesianAnalysisReporting2021
  @Vehtari.etal2017
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.align = "center",
  warning = FALSE,
  message = FALSE
)

library(data.table)
library(brms)
library(bayesplot)
library(ggplot2)
library(ggpubr)
library(knitr)
```

# 1. Introduction

## Contexte

Ce tutoriel a été développé dans le cadre du 28e colloque du Chapitre Saint-Laurent, présenté le 29 Mai 2024 à l'Université Laval, Québec, Canada.

Nous verrons les concepts de base qui vous permettront d'implémenter des modèles hiérarchiques avec le logiciel R, et d'interpréter les résultats en utilisant l'inférence Bayésienne.

Les objectifs d'apprentissage sont :  

1. De se familiariser avec la théorie sur les modèles hiérarchiques
2. De reconnaître les variantes des modèles (H(G)LM, MH(G)LM)
3. D'implémenter un modèle hiéarchique avec R
4. D'interpréter les résultats avec l'inférence Bayésienne

## Jeu de données

Le jeu de données que nous utiliserons pour l'atelier se nomme ADORE et provient de l'article suivant :

[Schür, C., Gasser, L., Perez-Cruz, F., Schirmer, K., Baity-Jesi, M. (2023). A benchmark dataset for machine learning in ecotoxicology. *Scientific Data*, 10:718. https://doi.org/10.1038/s41597-023-02612-2](https://www.nature.com/articles/s41597-023-02612-2)

Vous pouvez trouver les données originales sur le portail du [Eawag Research Data Institutional Collection](https://opendata.eawag.ch/dataset/adore).

Le jeu de données ADORE contient une myriade d'informations sur des expériences écotoxicologiques effectuées sur des espèces de poisson, de crustacés, et d'algues. L'objectif des données ADORE est de concerter des informations sur la toxicité aquatique accrue de différents composés chimiques sur des espèces pour faire de la modélisation prédictive.

# 2. Une note sur l'inférence Bayésienne

L'inférence Bayésienne est une toute autre façon de penser pour la réalisation et l'interprétation d'analyses statistiques. Cela vous apparaîtra comme assez différent de ce à quoi vous êtes habitué.e.s si vous avez appris les statistiques classiques (fréquentistes).

## Le théorème de Bayes

En inférence Bayésienne, on se sert de nos connaissances à priori ainsi que des données pour faire de l'inférence. Nous pouvons représenter ceci avec le théorème de Bayes qui va comme suit :

$$P(H \mid E) = \frac{P(H) \ P(E \mid H)}{P(E)}$$
Pour résumer l'équation :  

- $P(H)$ est la probabilité d'observer notre hypothèse, c'est la distribution à priori
- $P(E)$ est la probabilité d'observer de nouvelles preuves sous toutes les hypothèses possibles
- $P(H \mid E)$ est la probabilité d'observer notre hypothèse selon l'évidence, c'est la distribution à postériori
- $P(E \mid H)$ est la probabilité d'observer l'évidence si notre hypothèse est vraie, c'est la distribution de vraisemblance


Plus intuitivement, on peut aussi l'illustrer comme suit :

```{r, echo = FALSE, out.width = "100%", fig.align = "center", fig.cap = "Illustration du théorème de Bayes issue de Yanagisawa et al. 2019"}
knitr::include_graphics("images/bayes-inf.png")
```

**Ainsi, l'inférence Bayésienne est une approche où l'on adapte nos connaissances (à posteriori) à partir de nos hypothèses (connaissances à priori) et des preuves que nous avons.**

La distribution à posteriori est donc l'élément central que nous cherchons à estimer. Rappelez-vous que chaque fois que vous voyez le terme "à posteriori" dans ce tutoriel, nous faisons référence à la distribution d'un paramètre d'intérêt estimé par le modèle.

En prime, voici un lien vers une application qui vous permet de jouer avec ces trois distributions pour mieux comprendre comment les connaissances à priori et les preuves modifient la distribution à posteriori : 

https://micl.shinyapps.io/prior2post/

## Méthode d'estimation

Il existe de nombreuses façons d'approximer la distribution à posteriori. Dans ce tutoriel, nous utiliserons la méthode de Monte Carlo Hamiltonienne (HMC) et l'échantillonneur No-U-Turn (NUTS) pour estimer la distribution à posteriori. Ce sont des algorithmes spécifiques dans la grande famille d'estimation de Monte Carlo par chaîne de Markov (MCMC). 

Pour ce faire nous effectuerons tous nos modèles avec la librairie `brms`, une interface R pour le [langage probabiliste STAN](https://mc-stan.org/). La librairie `brms` utilise la méthode HMC et NUTS pour estimer les paramètres. Je vous recommande vivement de lire [les vignettes de la librairie](https://paul-buerkner.github.io/brms/articles/index.html) pour mieux comprendre les capacités et le fonctionnement de `brms`.

## Les avantages

L'inférence Bayésienne comporte certains avantages par rapport à l'approche statistique fréquentiste.

- Elle met l'accent sur la distribution et l'incertitude au lieu d'estimés uniques
- Elle permet une interprétation plus naturelle (probabiliste)
- On peut facilement critiquer les modèles

## Pour aller plus loin

La théorie sous-jacente au théorème de Bayes dépasse largement le cadre de ce tutoriel, donc veuillez consulter les ressources pertinentes dans la section Références. Une très bonne introduction que je ne peux recommander assez est l'excellent livre "Statistical Rethinking" de Richard McElreath. Richard McElreath publie également l'ensemble du contenu du livre sous forme de [vidéos sur YouTube](https://www.youtube.com/watch?v=FdnMWdICdRs&list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus).

# 3. Structure des données

## Description générale

Pour l'atelier, nous utiliserons une version des données nettoyées et prêtes pour l'analyse qui se trouvent sur [ce dépôt GitHub](https://github.com/quantitative-ecologist/Atelier-CSL-EcotoQ) dans le dossier [data](https://github.com/quantitative-ecologist/Atelier-CSL-EcotoQ/tree/main/data). Ce dépôt a été préparé spécifiquement pour l'atelier.

Voici les spécifications :

1. Le premier jeu de données servira à faire des modèles hiérarchiques univariés que nous appliquerons aux données d'animaux seulement. Nous l'appelerons `anim`.

2. Le second jeu de données nous servira à faire des modèles hiérarchiques multivariés que nous appliquerons aux données d'algues. Nous l'appelerons `algue`.

Importons les données à partir du dépôt GitHub de l'atelier :

```{r donnees}
github <- "https://raw.githubusercontent.com/quantitative-ecologist"
depot <- "Atelier-CSL-EcotoQ"
dossier <- "main/data"

anim <- fread(
  file.path(github, depot, dossier, "animal_dat.csv"),
  stringsAsFactors = TRUE
)

algue <- fread(
  file.path(github, depot, dossier, "algae_dat.csv"),
  stringsAsFactors = TRUE
)
```

## Variables

Une description détaillée des variables du jeu de données est présentée en Annexe de l'article de [Schür et al. (2023)](https://www.nature.com/articles/s41597-023-02612-2).

Dans le cadre de cet atelier, nous utiliserons un échantillon de ces variables.

### Variables sur les résultats expérimentaux (Y)

- `result_effect`: le groupe d'effet de l'expérience, soit, mortalité (`MOR`), physiologie (`PHY`), croissance (`GRO`), ou populationel (`POP`).
- `result_obs_duration_mean`: la durée d'exposition en heure codée comme `24`, `48`, `72`, et `96` heures
- `result_conc1_mean_binary`: si la dose est moins toxique (`0`) ou plus toxique (`1`)
- `result_conc1_type`: le type de concentration, soit, ingrédient actif (`A`), formulation (`F`), ou total (`T`)
- `result_conc_mean`: la concentration effective moyenne en mg/L
- `result_conc_mean_log`: le log de la concentration effective moyenne

### Variables sur les espèces (X)

- `tax_group`: le groupe taxonomique soit, `fish`, `crusta`, `algae`
- `tax_gs`: le nom de l'espèce étudiée codée comme `Genre_épithète`
- `tax_eco_food`: la position trophique de l'espèce. On y trouve les Bactérivores, Carnivores, Détritivores, Herbivores, Omnivores, Planktivores, Charognards, et les Parasites, toutes encodées avec la première lettre de leur nom
- `tax_lh_amd`: la longévité de l'espèce en jours
- `tax_lh_licm`: la taille corporelle ultime en cm
- `tax_lh_ri#/d`: le taux reproducteur en nombre d'individus produits par jour

### Variables liées aux conditions expérimentales (X)

- `test_exposure_type`: le type d'exposition, soit, statique (`S`), en flux continu d'eau (`F`), en flux continu d'eau avec renouvellement (`R`), ou non rapporté (`NR`).
- `test_media_type`: le type de médium utilisé, soit eau fraîche (`FW`) ou eau salée (`SW`)
- `media_ph_mean`: le pH moyen du medium
- `media_temperature_mean`: la température moyenne du medium en degrés Celsius
- `chem_name`: le nom du composé chimique à l'étude

Pour l'atelier, nous allons nous intéresser à modéliser les variables liées aux **résultats expérimentaux**. Ce seront donc nos variables réponse ($Y$). Nous testerons comment ces variables changent en fonction des variables liées aux espèces ainsi qu'aux conditions expérimentales ($X$)

# 4. Exploration des données

## Distribution de la concentration effective

Commençons par évaluer la distribution de la variable réponse, qui est le log de la concentration effective moyenne. Nous allons faire nos graphiques avec la librairie `ggplot2` et `ggpubr`.

```{r explo1, cache=TRUE, class.source="fold-hide"}
p1 <- ggplot(data = anim) +
  geom_histogram(
    aes(x = result_conc1_mean_log),
    color = "black", fill = "#440154"
  ) +
  ggtitle("Animaux") +
  ylab("Compte") +
  xlab("log(concentration moyenne (mg/L))") +
  theme_bw(base_size = 14) +
  theme(panel.grid = element_blank())

p2 <- ggplot(data = algue) +
  geom_histogram(
    aes(x = result_conc1_mean_log),
    color = "black", fill = "#7ad151"
  ) +
  ggtitle("Algues") +
  ylab("Compte") +
  xlab("log(concentration moyenne (mg/L))") +
  theme_bw(base_size = 14) +
  theme(panel.grid = element_blank())
```

Affichons les graphiques.

```{r plot1, fig.height=4, fig.width=8, cache=TRUE, class.source="fold-hide"}
ggarrange(p1, p2)
```

## Concentration effective selon l'espèce

Vérifions si les concentrations effectives varient selon l'espèce.

```{r explo2, cache=TRUE, class.source="fold-hide"}
p3 <- ggplot(data = anim) +
  geom_boxplot(
    aes(
      x = result_conc1_mean_log,
      y = tax_gs,
      fill = tax_group
    ),
    color = "black"
  ) +
  ggtitle("Animaux") +
  ylab("Espèce") +
  xlab("log(concentration moyenne (mg/L))") +
  scale_fill_manual(values = c("#21918c", "#440154")) +
  scale_x_continuous(
    breaks = seq(-8, 8, 4),
    limits = c(-9, 9)
  ) +
  theme_bw(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = "top"
  )

p4 <- ggplot(data = algue) +
  geom_boxplot(
    aes(x = result_conc1_mean_log, y = tax_gs),
    color = "black", fill = "#7ad151"
  ) +
  ggtitle("Algues") +
  ylab("Espèce") +
  xlab("log(concentration moyenne (mg/L))") +
  scale_x_continuous(
    breaks = seq(-4, 4, 2),
    limits = c(-5, 5)
  ) +
  theme_bw(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = "top"
  )
```

On affiche les graphiques.

```{r plot2, fig.height=6, fig.width=8, cache=TRUE, class.source="fold-hide"}
ggarrange(p3, p4, common.legend = TRUE)
```

## Concentration effective selon la position trophique

Pour les animaux, on pourrait aussi se demander si la concentration varie selon la position trophique, sachant que l'alimentation pourrait influencer l'exposition aux contaminants.

```{r explo3, cache=TRUE, class.source="fold-hide"}
p5 <- ggplot(data = anim) +
  geom_boxplot(
    aes(
      x = result_conc1_mean_log,
      y = tax_eco_food,
      fill = tax_group
    ),
    color = "black"
  ) +
  ggtitle("Animaux") +
  ylab("Position trophique") +
  xlab("log(concentration moyenne (mg/L))") +
  scale_fill_manual(values = c("#21918c", "#440154")) +
  scale_x_continuous(
    breaks = seq(-8, 8, 4),
    limits = c(-9, 9)
  ) +
  theme_bw(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    legend.position = "top"
  )
```

On affiche le graphique.

```{r plot3, fig.height=6, fig.width=6, cache=TRUE, class.source="fold-hide"}
p5
```

La variation semble un peu plus faible. On pourrait supposer que celà est dû au fait que les animaux sont exposés aux contaminants en conditions contrôlées, et non dans la nature.

## Concentration effective selon l'exposition

Finalement, on peut aussi se douter que le type d'exposition devrait influencer comment la concentration effective change.

```{r explo4, cache=TRUE, class.source="fold-hide"}
p6 <- ggplot(data = anim) +
  geom_boxplot(
    aes(
      x = result_conc1_mean_log,
      y = test_exposure_type,
      fill = tax_group
    ),
    color = "black"
  ) +
  ggtitle("Animaux") +
  ylab("Type d'exposition") +
  xlab("log(concentration moyenne (mg/L))") +
  scale_fill_manual(values = c("#21918c", "#440154")) +
  scale_x_continuous(
    breaks = seq(-8, 8, 4),
    limits = c(-9, 9)
  ) +
  theme_bw(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    legend.position = "top"
  )

p7 <- ggplot(data = algue) +
  geom_boxplot(
    aes(
      x = result_conc1_mean_log,
      y = test_exposure_type
    ),
    color = "black", fill = "#7ad151"
  ) +
  ggtitle("Algues") +
  ylab("Type d'exposition") +
  xlab("log(concentration moyenne (mg/L))") +
  scale_x_continuous(
    breaks = seq(-4, 4, 2),
    limits = c(-5, 5)
  ) +
  theme_bw(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    legend.position = "top"
  )
```

On affiche les graphiques.

```{r plot4, fig.height=5, fig.width=8, cache=TRUE, class.source="fold-hide"}
ggarrange(p6, p7, common.legend = TRUE)
```

## Sommaire de l'exploration de données

Les vérifications de nos données nous indiquent qu'il semble y avoir une structure hiérarchique dans nos données. En termes simples, cela signifie qu'il semble y avoir de la variation dans les concentrations effectives entre les différents groupes que nous avons vu.

Les modèles hiérarchiques nous permettront de modéliser cette variation afin d'en tenir compte. Nous verrons celà à la section 7.

# 5. Rappel sur les modèles linéaires

## Les bases

L'objectif d'un modèle linéaire est de calculer des prédictions ($\hat{Y}$) d'une variable $Y$ tout en minimisant l'écart entre les observations et les prédictions.

Au travers votre parcours, vous avez sûrement vu différents types de modèles où on utilise des variables explicatives $X_i$ pour prédire une variable $Y$ (ex. ANOVA, régression, ANCOVA). Par exemple, une régression linéaire peut s'écrire avec cette équation :

$$Y = X\beta+\epsilon$$

Où : 

- $Y$ est le vecteur des valeurs observées (c.-à.-d. la variable réponse)
- $X$ est la matrice de variables explicatives (incluant l'ordonnée à l'origine)
- $\beta$ est le vecteur de coefficients
- $\epsilon$ est le vecteur des résidus

Visuellement, on peut représenter ce modèle avec la figure suivante :

```{r plot5, fig.height=5, fig.width=6, echo=FALSE, cache=TRUE}
# Simulate data
set.seed(123)
n <- 120
rho <- 0.5
x  <- rnorm(n = n, mean = 10, sd = 5)
x <- ifelse(x < 0, 0, x)
y  <- (rho * x) + sqrt(1 - rho * rho) * rnorm(n = n, mean = 10, sd = 5)
y <- ifelse(y < 0, 0, y)

# Combine into a data frame
data <- data.frame(x = x, y = y)

# Fit model and plot
fit <- lm(formula = y ~ x, data = data)
data$predicted <- predict(fit)

# Get the model coefficients
coefficients <- coef(fit)
intercept <- round(coefficients[1], 2)
slope <- round(coefficients[2], 2)
r2 <- format(round(summary(fit)$adj.r.squared, 2), nsmall = 2)

# Create the equation string
equation <- paste0("Y = ", intercept, " + ", slope, " * X")
r2_p <- paste0("R² ajusté = ", r2)

ggplot(data, aes(y = y, x = x)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", formula = y ~ x, colour = "dodgerblue") +
  #geom_abline(intercept = coefficients[1], slope = coefficients[2]) +
  geom_segment(
    aes(xend = x, yend = predicted),
    color = "#6a6a6a",
    linetype = "dashed"
  ) +
  annotate(
    "text",
    x = min(data$x), y = max(data$y),
    label = equation, hjust = 0,
    size = 4, color = "#646262"
  ) +
  annotate(
    "text",
    x = min(data$x), y = max(data$y) - 2,
    label = r2_p, hjust = 0,
    size = 4, color = "#646262"
  ) +
  ylab("Y") +
  xlab("X") +
  scale_y_continuous(
    breaks = seq(0, 32, 8),
    limits = c(0, 34)
  ) +
  scale_x_continuous(
    breaks = seq(0, 20, 5),
    limits = c(0, 21)
  ) +
  theme_bw(base_size = 14) +
  theme(panel.grid = element_blank())
```

Pour interpréter les résultats d'un modèle linéaire, il est essentiel que celui-ci respecte **ces conditions d'application** :  

1. **Linéarité**: la relation entre $Y$ et $X$ est linéaire.
2. **Indépendance**: les observations sont indépendantes l'une de l'autre.
3. **Homoscédasticité**: la variance des résidus est homogène le long des valeurs prédites.
3. **Normalité des résidus**: les résidus suivent une distribution Gaussienne.

## Limites des modèles linéaires

Une des limites majeures des modèles linéaires classiques est qu'ils ne peuvent s'ajuster à des variables réponse pour lesquelles les résidus suivent une distribution non-Gaussienne.

Cette situation est particulièrement commune lorsqu'on analyse des données biologiques, qui ont tendance à suivre d'autres types de distribution telle que de type Poisson ou binomiale.

Dans la section suivante, nous verrons comment les modèles linéaires généralisés nous permettent de palier à ce problème en modélisant spécifiquement la nature des résidus d'une variable $Y$.

# 6. Modèles linéaires généralisés

Dans cette section, nous verrons comment implémenter des modèles linéaires généralisés (GLM) dans R en spécifiant la nature de la distribution des résidus.

Cela va nous permettre de modéliser nos variables sans avoir à les transformer.

## Familles de distribution

Il existe une multitude de familles de distribution pour décrire une variable. Ultimement, l'important est de retenir que chaque distribution a ses propres paramètres pour décrire sa forme. Ces paramètres seront utilisés pour l'interprétation statistique de nos modèles.

Voici trois exemples des familles les plus communes.

### Distribution de Poisson

Certaines distributions sont **discrètes**, et décrivent des nombres entiers exclusivement, tel que la distribution de **Poisson**. On voit souvent la distribution de Poisson dans les données écologiques comme l'abondance d'espèces ou le nombre d'individus d'une espèce. La distribution de Poisson est décrite par un seul paramètre qui est $\lambda$ qui décrit sa moyenne et sa variance.

Voici une représentation de cette distribution avec différentes valeur de $\lambda$ :

```{r plot6, fig.height=4, fig.width=10, echo=FALSE, cache = TRUE}
# Simulate data for each Poisson distribution
set.seed(123)
lambdas <- c(1, 4, 10)
n <- 1000
poisson <- data.frame(
  x = rep(1:n, times = length(lambdas)),
  lambda = rep(lambdas, each = n),
  y = c(
    rpois(n, lambdas[1]),
    rpois(n, lambdas[2]),
    rpois(n, lambdas[3])
  )
)

# Convert lambda to a factor for plotting purposes
poisson$lambda <- factor(
  poisson$lambda,
  levels = lambdas,
  labels = paste0("lambda = ", lambdas)
)

# Plot the three Poisson distributions using ggplot2
ggplot(
  data = poisson,
  aes(x = y)
) +
  geom_histogram(
    binwidth = 1,
    position = "dodge",
    colour = "black",
    fill = "darkgray"
  ) +
  facet_wrap(~ lambda) +
  labs(
    x = "Valeur",
    y = "Fréquence"
  ) +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank()
  )
```

### Distribution de Bernoulli

Une autre distribution communément utilisée est la distribution de Bernoulli, qui ne prend qu'un seul paramètre étant la probabilité de succès $p$ lorsqu'on a données de type 0 ou 1. On observe souvent ces données avec des présences-absences d'espèces, soit, typiquement lorsqu'une variable n'a que deux issues.

Cette distribution considère l'issue (0, 1) pour une seule expérience ou essai.

Voici une représentation de cette distribution avec différentes valeur de $p$ :

```{r plot7, fig.height=4, fig.width=10, echo=FALSE, cache=TRUE}
# Simulate data for each Bernoulli distribution
set.seed(123)
probs <- c(0.1, 0.5, 0.9)
n <- 1000
bernou <- data.table(
  sample = rep(1:n, times = length(probs)),
  probability = rep(probs, each = n),
  value = c(rbinom(n, size = 1, prob = probs[1]), 
            rbinom(n, size = 1, prob = probs[2]), 
            rbinom(n, size = 1, prob = probs[3]))
)

# Calculate the proportions
bernou[, count := .N, by = .(probability, value)]
bernou[, proportion := count / 1000, by = probability]

# Convert probability to a factor for plotting purposes
bernou[
  , probability := factor(
    probability,
    levels = probs,
    labels = paste0("p = ", probs)
  )
]

bernou <- unique(bernou[, .(probability, value, proportion)])

# Plot
ggplot(
  data = bernou,
  aes(x = factor(value), y = proportion)
) +
  geom_bar(
    stat = "identity",
    position = "dodge",
    colour = "black",
    fill = "darkgray"
  ) +
  facet_wrap(~ probability) +
  labs(
    x = "Valeur",
    y = "Probabilité"
  ) +
  scale_y_continuous(breaks = seq(0, 1, 0.25), limits = c(0, 1)) +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank()
  )
```

### Distribution binomiale

Finalement, la distribution binomiale est aussi communément observée dans les données biologiques, et consiste en une extension de la distribution de Bernoulli lorsqu'on répète l'essai à plusieurs reprises.

Elle consiste donc en le nombre de succès pour un nombre fixe d'expériences indépendantes, ou chaque essai a la même probabilité de succès $p$. Ses paramètres sont le nombre d'essais $n$ et la probabilité à chaque essai $p$.

Voici une représentation de cette distribution avec différentes valeur de $p$ et un $n$ de 50 :

```{r plot8, fig.height=4, fig.width=10, echo=FALSE, cache=TRUE}
# Simulate data for each Binomial distribution
set.seed(123)
probs <- c(0.1, 0.5, 0.9)
n <- 50

binom <- lapply(probs, function(p) {
  data.frame(
    probability = paste0("p = ", p),
    value = rbinom(n, size = n, prob = p)
  )
})
binom <- do.call(rbind, binom)

# Plot
ggplot(binom, aes(x = value)) +
  geom_histogram(
    aes(y = after_stat(density)),
    binwidth = 1, position = "dodge",
    colour = "black",
    fill = "darkgray"
  ) +
  facet_wrap(~ probability) +
  labs(
    x = "Nombre de fois qu'on obtient 1",
    y = "Probabilité"
  ) +
  scale_y_continuous(
    breaks = seq(0, 1, 0.25),
    limits = c(0, 1)
  ) +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "none",
    panel.grid = element_blank()
  )
```

## Fonction de lien

Nous avons vu trois exemples de distributions souvent rencontrées avec des données biologiques.

Dans un GLM, afin que celui-ci puisse estimer la relation entre $Y$ et $X$, on doit donc :

1. Spécifier la distribution des résidus
2. Spécifier la fonction de lien pour les valeurs prédites

Cette deuxième étape consiste à linéariser la relation entre $Y$ et $X$ pour ensuite pouvoir faire des interprétations. Il s'agit donc de transformer les valeurs prédites $\hat{Y}$ pour avoir une relation linéaire.

Mathématiquement, le prédicteur linéaire dans un GLM est défini comme :

$$\eta = X\beta$$

où $\beta$ sont les coefficients et $X$ la matrice des variables.

La fonction de lien transforme le prédicteur linéaire à l'échelle appropriée pour $Y$ tel que :

$$g(\mu) = \eta$$

où $\mu$ est la moyenne prédite de $Y$ en fonction des prédicteurs $X$, et $g(.)$ est la fonction de lien.

Voici une table qui résume les informations relatives à la fonction de lien pour les familles que nous avons vu.

```{r echo = FALSE}
library(knitr)
link_info <- data.frame(
  Distribution = c("Gaussienne", "Poisson", "Bernoulli", "Binomial"),
  Nom = c("Identité", "Log", "Logit", "Logit"),
  Fonction_de_lien = c(
    "$g(\\mu) = \\mu$",
    "$g(\\mu) = \\log(\\mu)$",
    "$g(\\mu) = \\log\\left(\\frac{\\mu}{1 - \\mu}\\right)$",
    "$g(\\mu) = \\log\\left(\\frac{\\mu}{1 - \\mu}\\right)$"
  ),
  Modèle = c(
    "$\\mu = \\mathbf{X} \\boldsymbol{\\beta}$",
    "$\\log(\\mu) = \\mathbf{X} \\boldsymbol{\\beta}$",
    "$\\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\mathbf{X} \\boldsymbol{\\beta}$",
    "$\\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\mathbf{X} \\boldsymbol{\\beta}$"
  ),
  brms = c(
    "`gaussian(link=\"identity\")`",
    "`poisson(link=\"log\")`",
    "`bernoulli(link=\"logit\")`",
    "`binomial(link=\"logit\")`"
  )
)

# Print the kable table
kable(
  link_info, align = "l",
  escape = FALSE
)
```

# 7. GLM avec les données ADORE

Maintenant que nous avons vu comment fonctionne le familles de distribution ainsi que la fonction de lien, nous pouvons estimer les paramètres d'un GLM avec R.

Nous allons construire un modèle simple avec une variable réponse et deux covariables.

Nos variable sont :

- $Y$ : si la concentration effective est 1, plus toxique, ou 0, moins toxique.
- $X_1$ : le type d'exposition
- $X_2$ : la température moyenne du medium degrés Celsius
- $X_3$ : la longévité de l'espèce en jours

Évaluons leur structure avant de faire le modèle.

```{r}
str(anim[
  , .(
    result_conc1_mean_binary, test_exposure_type,
    tax_lh_amd, media_temperature_mean
  )
])
```

Les données sont dans le format adéquat et sont prêtes pour la modélisation.

Si on essayait modéliser la relation entre la concentration effective (plus toxique ou moins toxique) et la température du medium avec une régression linéaire classique, on obtiendrait ceci :

```{r plot9, fig.height=4, fig.width=9, echo=FALSE, cache=TRUE}
fit2 <- lm(
  result_conc1_mean_binary ~ media_temperature_mean,
  data = anim
)

out2 <- data.frame(residuals = resid(fit2), fitted = fitted(fit2))

pex1 <- ggplot(
  data = anim,
  aes(x = media_temperature_mean, y = result_conc1_mean_binary)
) +
  geom_point(alpha = 0.05) +
  geom_abline(
    intercept = fit2$coefficients[1],
    slope = fit2$coefficients[2],
    color = "dodgerblue", linewidth = 1
  ) +
  ylab("Niveau de toxicité") +
  xlab("Température moyenne du médium") +
  scale_y_continuous(
    breaks = seq(0, 1, 0.25),
    limits = c(0, 1)
  ) +
  theme_bw(base_size = 14) +
  theme(panel.grid = element_blank())

pex2 <- ggplot(
  data = out2,
  aes(x = fitted, y = residuals)
) +
  geom_point(alpha = 0.05) +
  geom_abline(
    intercept = 0,
    slope = 0,
    linewidth = 1,
    linetype = "dashed",
    color = "dodgerblue"
  ) +
  ylab("Résidus normalisés") +
  xlab("Valeurs prédites") +
  scale_y_continuous(
    breaks = seq(-0.8, 0.8, 0.4),
    limits = c(-0.8, 0.8)
  ) +
  theme_bw(base_size = 14) +
  theme(panel.grid = element_blank())

ggarrange(pex1, pex2)
```

Comme vous pouvez voir dans le panneau à gauche, le modèle ne décrit pas bien la relation entre le niveau de toxicité et la température. De plus, il aurait pu y avoir des cas où la droite dépasse le seuil possible de nos valeurs (ici 0 ou 1).

On peut voir à gauche que les résidus de notre modèle ne satisfont pas la condition d'homoscédasticité.

Pour ces raisons, on doit donc établir une limite inférieure et supérieure à nos données en spécifiant une distribution de Bernoulli pour modéliser la concentration effective.

## Préparation des données

Nous allons construire un GLM Bayésien en utilisant les variables spécifiées ci-haut.

Dans un premier temps, nous allons normaliser les variables explicatives pour faciliter l'interprétation et les ramener à la même échelle.

```{r}
# Fonction de normalisation en score Z.
standardize <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}

# Créer deux nouvelles colones
anim[
  , c("Ztax_lh_amd", "Zmedia_temperature_mean") := lapply(
    .SD,
    standardize
  )
  , .SDcols = c("tax_lh_amd", "media_temperature_mean")
]
```

## Construction du modèle

Voici la formule de notre modèle. On évalue donc comment la concentration effective varie selon le type d'exposition, la longévité moyenne de l'espèce, et la température du médium durant l'expérience.

Voici l'équation de notre modèle :

$$\eta = X\beta + Z\gamma + 1\beta_0 + \epsilon$$

où :

- $\eta$ est le prédicteur linéaire
- $X$ est la matrice de conception du type d'exposition
- $\beta$ est le vecteur des coefficients du type d'exposition
- $Z$ est la matrice de conception des prédicteurs linéaires (longévité et température)
- $\gamma$ est le vecteur des coefficients du type d'exposition des prédicteurs linéaires
- $1$ est le vecteur de 1 pour l'ordonnée à l'origine
- $\beta_0$ est l'ordonnée à l'origine pour le niveau de référence

La fonction de lien du modèle est :

$$logit(p) = log(\frac{p}{1-p})$$

où :

$p$ est la probabilité que la concentration effective soit toxique (1) pour chaque observation. 

On estime $p$ en utilisant l'inverse de la fonction logit :

$$p = \text{logit}^{-1}(\eta) = \frac{1}{1 + e^{-\eta}}$$

Spécifions ce modèle dans `brms` avec la fonction `brmsformula()` :

```{r}
form1 <- brmsformula(
  result_conc1_mean_binary ~
  test_exposure_type +
  Ztax_lh_amd +
  Zmedia_temperature_mean
)
```

## Informations à priori

Hypothèses...

```{r}

```

## Estimation des paramètres

Il est à noter qu'estimer un modèle par MCMC peut prendre un long temps, particulièrement lorsqu'il y a beaucoup de données et qu'on veut faire beaucoup d'itérations.

Pour cette raison, on peut tirer profit des coeurs dans votre ordinateur pour accélérer le processus. Toutefois, si vous avez un gros modèle à faire rouler, je suggère de l'effectuer sur un serveur de calcul si vous y avez accès.

Nous allons donc vérifier le nombre de coeur que nous avons. Si vous en avez seulement 4 ou moins, je vous suggère de passer cette étape.

```{r}
parallel::detectCores()
```

La fonction indique que j'ai 16 coeurs disponibles dans mon ordinateur. On doit toujours en réserver un pour les processus internes. Ainsi, je vais utiliser 12 coeurs qui effectueront un processus parallèle sur 4 chaînes.

Voici le calcul pour les spécifications des itérations de MCMC. Normalement, on veut que nos distributions postérieures contiennent 1000 échantillons par chaîne. Ainsi, pour chaque chaîne, nous aurons :

- n: 2000
- Itérations: n - réchauffement 
- Réchauffement: n / 2
- Échantillonnage: itérations / échantillonnage = 1000

Notre modèle fera donc 1000 réchauffements (`warmup = 1000`), 1000 itérations (`iter = 2000` où 2000-1000), et échantillonera une valeur de paramètre à chaque itération (`thin = 1`). Nous obtiendrons ainsi 4000 échantillons pour chaque distribution postérieure, soit, 1000 par chaîne.

Puisque j'utiliserai 12 coeurs en parallèle sur 4 chaînes, 3 coeurs seront sollicités par chaîne. Ceci est spécificé dans l'argument `threads = threading(3)`.

Nous sommes donc prêt.e.s à estimer les paramètres :

```{r glm1, cache=TRUE}
glm1 <- brm(
  # La formule et la famille
  formula = form1,
  family = bernoulli(link = "logit"),

  # Les paramètres d'itérations pour le MCMC
  iter = 2000,
  warmup = 1000,
  thin = 1,
  chains = 4,

  # Paramètres pour accélérer les calculs
  # Utiliser seulement si vous avez plusieurs coeurs
  threads = threading(3),
  backend = "cmdstanr",

  # Reproductibilité et paramètres de contrôle
  seed = 123,
  control = list(adapt_delta = 0.95),

  # Distributions à priori
  #prior = priors,
  sample_prior = TRUE,

  # Données
  data = anim
)
```

Puisque l'estimation peut prendre quelques temps, on créé un dossier où nous allons sauvegarder le modèle.

```{r}
chemin <- file.path(getwd(), "outputs")
dir.create(chemin)
```

On sauvegarde le modèle en format `.rds` qui pourra facilement être réimporté dans la session au besoin.

```{r}
saveRDS(
  object = glm1,
  file = file.path(chemin, "glm1.rds")
)
```

## Vérifications du modèle

Maintenant que notre modèle a terminé son exécution, il est essentiel de faire des inspections pour s'assurer que les paramètres estimés sont fiables. Ces étapes d'inspections sont cruciales pour s'assurer que nos interprétations biologiques font du sens. Autrement, nous pourrions avoir de mauvaises surprises.

Commençons par extraire les échantillons des distributions à posteriori dans un `data.frame` pour les manipuler.

```{r}
params <- as_draws_df(
  x = glm1, add_chain = TRUE,
  regex = TRUE
)
```

### Convergence des chaînes

La première chose que nous allons faire est de vérifier si les chaînes de Markov ont bien convergé pour chacun de nos paramètres d'intérêt. Nous allons faire ceci en inspectant des "trace plots".

Nous pouvons déduire que les chaînes ont convergé si les "trace plots" sont homogènes.

```{r plot10, cache=TRUE}
bayesplot::mcmc_trace(
  params,
  regex_pars = "b",
  np = nuts_params(glm1)
)
```

Les chaînes de notre modèle semble avoir très bien convergé.

Une autre étape d'inspection de convergence des chaînes de Markov est d'évaluer les **$\hat{R}$** et les **tailles d'échantillon effectives** pour chaque paramètre d'intérêt.

- Dans @Burkner2017, on peut lire que la taille d'échantillon effective est : "le nombre d'échantillons indépendants de la distribution postérieure qui serait attendu pour produire la même erreur standard de la moyenne postérieure que celle obtenue à partir des échantillons dépendants retournés par l'algorithme MCMC". Dans `brms`, le résumé du modèle fournit une estimation des tailles d'échantillon effectives de la partie centrale et des queues de la distribution postérieure. Le `Bulk_ESS` rapporte l'efficacité de l'échantillonnage de la partie centrale de la distribution postérieure (c'est-à-dire la médiane ou la moyenne), tandis que le `Tail_ESS` diagnostique l'efficacité de l'échantillonnage des queues de la distribution postérieure (c'est-à-dire les quantiles 5% et 95%). Nous utilisons un seuil de <100 comme règle de décision pour savoir si les chaînes ont convergé pour les paramètres [@Vehtari.etal2021a].

- En revanche, le $\hat{R}$ est un outil de diagnostic quantitatif courant pour savoir si les chaînes ont convergé [@gelmanBayesianDataAnalysis2013;@Burkner2017]. Il compare la variance à l'intérieur d'une chaîne à la variance entre les chaînes. Différentes versions et seuils ont été proposés pour cette mesure [@gelmanInferenceIterativeSimulation1992;@gelmanBayesianDataAnalysis2013;@Vehtari.etal2021a], mais nous utiliserons la plus parcimonieuse suggérée par @Vehtari.etal2021a avec un seuil fixé à <1.01.

Dans brms, le $\hat{R}$, le `Bulk_ESS`, et le `Tail_ESS` apparaissent toujours à côté des moyennes postérieures des paramètres affichées avec la fonction `summary()`. Examinons les valeurs pour nos paramètres :

```{r}
glm1_t <- data.table(
  round(summary(glm1, prob = 0.89, robust = TRUE)$fixed, digits = 3),
  keep.rownames = TRUE
)
setnames(glm1_t, old = "rn", new = "Parameter")

glm1_t[, c(1, 6:8)]
```

Les valeurs sont très bien!

### Ajustement du modèle

Nous allons maintenant examiner si notre modèle a bien prédit les données en utilisant les [vérifications prédictives postérieures](https://mc-stan.org/bayesplot/reference/PPC-overview.html). Les vérifications prédictives postérieures utilisent des données simulées à partir de la distribution prédictive postérieure d'un modèle et les comparent aux données brutes utilisées pour ajuster le modèle. @gabryVisualizationBayesianWorkflow2019 suggèrent qu'un modèle bien ajusté devrait générer des données ressemblant aux données qui ont été observées (bruts). Ici, $y$ est la distribution de nos données observées, et $y_{rep}$ est la distribution des données simulées à partir de la distribution prédictive postérieure du modèle.

La production des graphiques peut prendre du temps en fonction de la complexité du modèle et de la taille des données. Vous pouvez spécifier le nombre d'échantillons à afficher en utilisant l'argument `ndraws` dans la fonction `pp_check()` pour accélérer le processus.

```{r plot11, fig.height=5, fig.width=6, cache=TRUE}
pp_check(glm1, ndraws = 100)
```

Notre modèle semble très bien ajusté aux données!

En somme, nos inspections indiquent que le modèle est très bon. Toutefois, je vous encourage à consulter la section sur les inspections additionnelles pour mieux diagnostiquer vos modèles.

## Interprétations

### Sommaire des paramètres

Par défaut, la fonction `summary()` dans `brms` rapporte la moyenne de la distribution postérieure avec les intervales de compatibilité inférieurs et supérieurs à 95%.

Toutefois, il est suggéré en analyse Bayésienne de rapporter les intervalles à 89% car ils procurent davantage de stabilité. De plus, la médiane est une meilleure mesure de tendance centrale lorsque la distribution postérieure n'est pas symétrique. 

Nous avons donc ajouté des arguments à la fonction summary précédemment en faisant ce code :

```{r, eval=FALSE}
glm1_t <- data.table(
  round(summary(glm1, prob = 0.89, robust = TRUE)$fixed, digits = 3),
  keep.rownames = TRUE
)
setnames(glm1_t, old = "rn", new = "Parameter")
```

où `robust = TRUE` indique de rapporter la médiane, et `prop=0.89` les intervalles à 89%. Au final, la décision de l'intervalle et arbitraire, et le mieux est de visualiser la distribution entière de l'estimé.

Visualisons la table de sommaire :

```{r}
knitr::kable(glm1_t[, c(1, 2, 4, 5)])
```

On peut voir que :

- Il y a des différences de toxicité selon le type d'exposition
- La probabilité que la CL50 soit plus toxique augmente avec la longévité
- La probabilité que la CL50 soit plus toxique diminue avec la température moyenne

Nous allons visualiser ces résultats avec des figures.

### Figures

Tout d'abord, on extrait les prédictions pour la longévité moyenne ainsi que la température moyenne avec la fonction `conditional_effects()` qui est spécifique à `brms`. 

#### Température :

```{r}
tab1 <- conditional_effects(
  x = glm1, method = "posterior_epred",
  effects = "Zmedia_temperature_mean",
  spaghetti = TRUE, ndraws = 1000,
  mean = FALSE
)
spag1 <- attr(tab1$Zmedia_temperature_mean, "spaghetti")
```

#### Longévité

```{r}
tab2 <- conditional_effects(
  x = glm1, method = "posterior_epred",
  effects = "Ztax_lh_amd",
  spaghetti = TRUE, ndraws = 1000,
  mean = FALSE
)
spag2 <- attr(tab2$Ztax_lh_amd, "spaghetti")

```

#### Type d'exposition

Ici, on va utiliser tous les échantillons des distributions postérieures des moyennes prédites pour le type d'exposition afin de les comparer. Nous avons déjà extrait ceci dans une étape ultérieure et assigné à l'objet `params`. Visualisons l'objet :

```{r}
params
```

Nous allons utiliser les 4 premières colones pour produire le graphique. On va manipuler un peu la table pour faire le graphique.

```{r}
# Transformer en data.table pour manipuler
paramsdt <- data.table(params)

paramsdt[, c(2:4) := paramsdt[, c(2:4)] + b_Intercept]

# Changer en format long
preds3 <- melt(
  data = paramsdt[, c(1:4)],
  variable.name = "exposure_type",
  measure = colnames(paramsdt[, c(1:4)])
)

# Ramener à l'échelle de probabilité
preds3[, value := plogis(value)]

# Calculer les médianes
medians <- preds3[, .(median = median(value)), by = exposure_type]
```

```{r plot12, fig.height=5, fig.width=6, cache=TRUE}
ggplot(
  data = preds3,
  aes(x = value, fill = exposure_type)
) +
  geom_density(alpha = 0.25, colour = "black") +
  geom_vline(
    data = medians,
    aes(xintercept = median, color = exposure_type),
    linetype = "dashed"
  ) +
  scale_fill_discrete(
    labels = c(
      "Flux", "NS",
      "Renouvellement", "Statique"
    )
  ) +
  scale_colour_discrete(
    labels = c(
      "Flux", "NS",
      "Renouvellement", "Statique"
    )
  ) +
  #scale_x_continuous(breaks = seq(0.25, 1, 0.25), limits = c(0.25, 1)) +
  xlab("Probabilité d'être plus toxique") +
  ylab("Densité") +
  labs(fill = "Exposition", colour = "Exposition") +
  theme_classic(base_size = 14) +
  theme(legend.position = "top")
```



On peut maintenant produire les graphiques. À titre de rappel, on a la même pente pour l'ensemble des types d'exposition, et des ordonnées à l'origine qui diffèrent. Ici, on rapporte la droite pour le type d'exposition `F`, pour flux d'eau continu. 

```{r plot13, fig.height=4, fig.width=8, cache=TRUE, }
preds1 <- ggplot() +
  geom_point(
    data = anim,
    aes(
      y = result_conc1_mean_binary,
      x = Zmedia_temperature_mean
    ),
    alpha = 0.05
  ) +
  geom_line(
    data = spag1,
    aes(
      x = Zmedia_temperature_mean,
      y = estimate__,
      group = sample__
    ),
    linewidth = 1, alpha = 0.05,
    colour = "#440154"
  ) +
  ylab("Toxicité\n") +
  scale_y_continuous(
    breaks = seq(0, 1, 0.25),
    limits = c(0, 1)
  ) +
  xlab("\nTempérature moyenne normalisée") +
  theme_classic(base_size = 14)

preds2 <- ggplot() +
  geom_point(
    data = anim,
    aes(
      y = result_conc1_mean_binary,
      x = Ztax_lh_amd
    ),
    alpha = 0.05
  ) +
  geom_line(
    data = spag2,
    aes(
      x = Ztax_lh_amd,
      y = estimate__,
      group = sample__
    ),
    linewidth = 1, alpha = 0.05,
    colour = "#440154"
  ) +
  ylab("Toxicité\n") +
  scale_y_continuous(
    breaks = seq(0, 1, 0.25),
    limits = c(0, 1)
  ) +
  xlab("\nLongévité moyenne") +
  theme_classic(base_size = 14)

ggarrange(preds1, preds2)
```




# 7. Modèles linéaires (généralisés) hiérarchiques

problème de plusieurs paramètres quand on a plusieurs facteurs

Biological and ecological data are often messy. Most of the time there is an inherent structure to data (i.e. single observations are not always independent), relationships between variables of interest might differ depending on grouping factors like species, and more often than not sample sizes are low, making it difficult to fit models that require many parameters to be estimated.

# 8. Modèles linéaires (généralisés) hiérarchiques multivariés

# X. Informations complémentaires

## Inspections additionnelles

While the model verifications that we just did are probably among the most important ones, they cover only a small portion of the checks that you should perform to ensure that your model has been correctly specified. To go further, here is a list of useful links for additional checks : 

- [MCMC diagnostics](https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html) with the `bayesplot` package
- [Additional posterior predictive checks](https://mc-stan.org/bayesplot/articles/graphical-ppcs.html) with the `bayesplot` package
- [Additional residuals inspections](http://mjskay.github.io/tidybayes/articles/tidybayes-residuals.html) with the `tidybayes` package. For instance, you could inspect the relationship between the residuals and your fixed effects to see if the model failed at describing some features. This will be important for biological interpretations.
- [Leave-one-out cross-validation](https://link.springer.com/article/10.1007/s11222-016-9696-4) using Pareto-smoothed importance sampling for predictive performance and model comparisons. For important references consult the [loo FAQ](https://avehtari.github.io/modelselection/CV-FAQ.html), [the roaches model example](https://avehtari.github.io/modelselection/roaches.html), and the [loo package vignette](http://mc-stan.org/loo/articles/index.html)

Moreover, note that MCMC estimation can come with different convergence problems. Those problems can arise from different processes, but `brms` (and other packages using MCMC) should print warnings outlining the potential problems after the model has finished running. Here is a [useful link](https://mc-stan.org/misc/warnings.html) describing each of those problems and their solutions.

# References

<div id="refs"></div>

# Reproductibilité

Voici les informations minimales de mon système pour reproduire les analyses avec les mêmes versions de R ainsi que les librairies.

```{r sessionInfo}
sessionInfo()
```
